{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.6 (tensorflow)",
      "language": "python",
      "name": "rga"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "spacy_introduction_for_pvi_WS2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teddius/TensorFlow_Chatbot_for_20171128_Talk_BotsHub_Meetup_Vienna/blob/master/spacy_introduction_for_pvi_WS2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtWjtaMjoCHg"
      },
      "source": [
        "# Spacy Introduction for Programming Voice Interfaces WS2020\n",
        "* Author: [Andreas Rath](https://github.com/teddius) - andreas.rath@ondewo.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynkoPQdyoCHh"
      },
      "source": [
        "# How to NLP preprocessing text with Spacy, NLTK and Spelling Correction in Python\n",
        "\n",
        "Two key libraries for NLP with Python:\n",
        "\n",
        "* [NLTK](https://www.nltk.org/)\n",
        "* [Spacy](https://spacy.io/)\n",
        "* [SymSpell](https://github.com/wolfgarbe/SymSpell/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOslGx28qDb5"
      },
      "source": [
        "### Installing Spacy\n",
        "You can install Spacy with a simple PIP install. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ29xJBAqHzH",
        "outputId": "d8de284c-191f-452a-b324-d8cd813e4745"
      },
      "source": [
        "!pip install spacy tqdm "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u6v8UHIp93Y"
      },
      "source": [
        "You will need to ensure that you've installed a language with Spacy.  If you do not, you will get the following error:\n",
        "\n",
        "```\n",
        "OSError: [E050] Can't find model 'en_core_web_sm'. It doesn't seem \n",
        "to be a shortcut link, a Python package or a valid path to a \n",
        "data directory.\n",
        "```\n",
        "\n",
        "To install English, use the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCpIbBONqNYO",
        "outputId": "2efe029b-9fb1-4c70-c663-21e0ea8f4946"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m‚úî Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUm0nliEq2t9"
      },
      "source": [
        "# Import Spacy library\n",
        "import spacy\n",
        "\n",
        "# load the English web corpus small which we just downloaded \n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Bp1_n4oCHh"
      },
      "source": [
        "### First step: Tokenization\n",
        "\n",
        "Tokenization is the task of splitting text into tokens while removing characters, such as punctuation.\n",
        "\n",
        "Lets try a couple of examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38T9-M_UoCHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b887f13-3399-4ff6-9d62-f73898136384"
      },
      "source": [
        "doc = nlp(u\"My name is Andreas!\")\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My\n",
            "name\n",
            "is\n",
            "Andreas\n",
            "!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYVopr98rYpN",
        "outputId": "058602da-0bca-465b-d858-409fd5e8f6d2"
      },
      "source": [
        "# Sometimes tokenization is not perfect => check 1. and 2. will be 4 tokens\n",
        "doc = nlp(u\"Hi Peter, can you please check the 1. and 2. example, while I board the plain to the U.K.?\")\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi\n",
            "Peter\n",
            ",\n",
            "can\n",
            "you\n",
            "please\n",
            "check\n",
            "the\n",
            "1\n",
            ".\n",
            "and\n",
            "2\n",
            ".\n",
            "example\n",
            ",\n",
            "while\n",
            "I\n",
            "board\n",
            "the\n",
            "plain\n",
            "to\n",
            "the\n",
            "U.K.\n",
            "?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSTrVTrSr-at",
        "outputId": "20ae1698-b632-46e3-a5bc-6fd3812eecf0"
      },
      "source": [
        "doc = nlp(u\"The URL is http://www.gmx.at.\")\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The\n",
            "URL\n",
            "is\n",
            "http://www.gmx.at\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JFqbfDroCHh"
      },
      "source": [
        "### Second step: Stop Words\n",
        "\n",
        "Stop words are words which are filtered out before or after processing of natural language text. Spacy includes lists of stop words for each langauge you can use right away. \n",
        "\n",
        "For intent classification in voice interfaces it is important to remove stop words like \"ah\", \"mhm\", \"please\", \"indeed\" etc. etc.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUqV3qUzvs15",
        "outputId": "f9811ebe-3df1-4ee5-e32a-f98fda4d16c4"
      },
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "print(STOP_WORDS)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'again', 'none', 'what', 'whenever', 'anyone', 'one', 'whom', 'all', 'give', '‚Äòre', 'had', 'six', 'themselves', 'you', 'those', 'rather', 'up', 'whoever', 'as', 'made', 'hereupon', 'in', 'always', 'because', 'seeming', 'bottom', 'but', 'top', 'therein', 'off', 'unless', 'who', 'first', 'such', 'several', 'either', 'former', 'might', 'thereupon', 'has', 'herself', 'five', 'thru', 'thereby', 'doing', 'to', 'serious', 'within', 'however', 'keep', 'nowhere', 'there', 'are', 'some', 'how', 'now', 'alone', 'formerly', 'namely', 'n‚Äòt', 'about', 'along', \"'m\", 'n‚Äôt', 'nobody', 'which', 'whatever', 'very', 'she', 'himself', 'various', 'ours', 'since', 'still', 'him', 'well', 'eight', 'twelve', 'whose', 'will', 'beforehand', 'amount', 'they', 'via', 'even', 'least', 'throughout', 'while', 'his', 'why', 'were', 'nothing', 'another', 'anyway', 'forty', 'seems', 'this', 'until', 'these', 'whither', 'cannot', 'put', 'its', 'whence', \"'d\", 'most', 'own', 'our', 'her', 'whereupon', 'much', 'ever', 'yourselves', 'can', 'empty', 'enough', 'should', 'sixty', 'been', 'regarding', 'thus', \"'re\", '‚Äôre', 'then', 'become', 'make', 'using', 'with', 'above', 'back', 'have', 'same', 'twenty', 'not', 'else', 'or', 'quite', 'be', \"'ve\", 'really', 'your', \"n't\", 'did', 'besides', 'mostly', 'and', 'four', 'three', 'whereafter', 'wherein', \"'s\", 'after', 'never', 'under', 'though', 'less', 'during', 'due', 'itself', 'below', 'hereby', 'meanwhile', 'by', 'toward', 'at', 'is', 'take', 'am', 'therefore', 'when', 'here', 'than', 'would', 'show', '‚Äôve', 'seemed', 'except', 'myself', 'where', 'each', 'wherever', 'becoming', 'yours', 'nevertheless', 'nine', 'almost', 'behind', 'a', 'from', 'latterly', 'neither', 'before', 'of', 'only', 'everything', 'next', 'full', 'the', '‚Äòs', 'somehow', 'call', '‚Äôm', 'thence', 'every', '‚Äòm', 'ourselves', 'my', 'over', 'last', 'so', 'noone', 'often', 'if', 'into', '‚Äòll', 'do', 'also', 'does', 'further', 'he', 'whereas', 'name', 'through', '‚Äôd', 'per', 'beyond', 'towards', 'their', 'eleven', 'go', 'nor', 'anywhere', 'many', 'once', 'two', 'herein', 'anything', 'whole', 'move', 'someone', 'yourself', 'around', 'say', 'otherwise', 'beside', 'sometimes', '‚Äôs', 'too', 'out', 'fifty', 'upon', 'i', 'already', 'between', 'it', 'that', 'down', 'any', 'front', 'get', 'anyhow', 'just', 'no', 'latter', 'on', 'ten', 'an', \"'ll\", 'more', 'whether', 'mine', 'me', 'ca', 'somewhere', 'among', 'becomes', 'other', 'everywhere', 'must', 'third', 're', '‚Äôll', 'something', 'us', 'please', 'used', 'indeed', 'few', 'onto', 'whereby', 'sometime', 'without', 'hereafter', 'although', 'both', 'hers', 'fifteen', 'could', 'amongst', 'everyone', 'hence', 'part', 'perhaps', 'side', 'for', 'we', 'across', 'hundred', 'may', 'thereafter', 'them', 'together', 'yet', 'others', 'seem', '‚Äòve', 'was', 'moreover', '‚Äòd', 'see', 'being', 'done', 'against', 'afterwards', 'became', 'elsewhere'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy3AFl3HoCHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb734be-42d7-439e-c422-4e451ecd1f3c"
      },
      "source": [
        "doc = nlp(u\"I like a red apple please\")\n",
        "for token in doc:\n",
        "    if token.text not in STOP_WORDS:\n",
        "      print(token.text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "like\n",
            "red\n",
            "apple\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shkfDnkKxQWe",
        "outputId": "c87a6bac-18ce-49dd-af78-96953dfc23f4"
      },
      "source": [
        "doc = nlp(u\"I like one red apple please\")\n",
        "for token in doc:\n",
        "    if token.text not in STOP_WORDS:\n",
        "      print(token.text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "like\n",
            "red\n",
            "apple\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5XF-6VqySgc",
        "outputId": "e0bad4df-36f3-49ed-be4c-a6475143b76b"
      },
      "source": [
        "doc = nlp(u\"I would very much like a red apple please\")\n",
        "for token in doc:\n",
        "    if token.text not in STOP_WORDS:\n",
        "      print(token.text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "like\n",
            "red\n",
            "apple\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd298grhxWvW"
      },
      "source": [
        "**WARNING: Always check your stop word list if ok for your use case**\n",
        "STOP WORD lists are great but sometimes contain your \"entities\" or key words you need for your \"intent detection\" - so you need to make sure that you remove them from the stop word list so you are not loosing them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3-hvsgdxM63",
        "outputId": "5bf58ab3-93c8-43f4-81b4-6c12e2c82c1d"
      },
      "source": [
        "doc = nlp(u\"Place red apple in box\")\n",
        "for token in doc:\n",
        "    if token.text not in STOP_WORDS:\n",
        "      print(token.text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Place\n",
            "red\n",
            "apple\n",
            "box\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8NPD0OaxKxD",
        "outputId": "c8aa6c6b-6cb6-41f3-924e-c60d36ecd4bf"
      },
      "source": [
        "doc = nlp(u\"Place red apple next to box\")\n",
        "for token in doc:\n",
        "    if token.text not in STOP_WORDS:\n",
        "      print(token.text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Place\n",
            "red\n",
            "apple\n",
            "box\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQoxxjg5yycz",
        "outputId": "a4815efc-bcf6-449a-9cc1-c3fd024e9cf6"
      },
      "source": [
        "doc = nlp(u\"Place red apple on top of box\")\n",
        "for token in doc:\n",
        "    if token.text not in STOP_WORDS:\n",
        "      print(token.text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Place\n",
            "red\n",
            "apple\n",
            "box\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCP0Xc7M6oJ0"
      },
      "source": [
        "### Third step: Text Normalization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXUhky909Hi5"
      },
      "source": [
        "#### Stemming\n",
        "\n",
        "\n",
        "In linguistic morphology and information retrieval, stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form‚Äîgenerally a written word form. \n",
        "=> https://en.wikipedia.org/wiki/Stemming \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBHvWN7l9rMN",
        "outputId": "0a5fa058-00ff-4cce-ccea-28631da7ffde"
      },
      "source": [
        "# Porter Stemmer\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "tokens = ['compute', 'computer', 'computed', 'computing']\n",
        "for token in tokens:\n",
        "    print(token + ' --> ' + stemmer.stem(token))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compute --> comput\n",
            "computer --> comput\n",
            "computed --> comput\n",
            "computing --> comput\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtugV7sr9TYC",
        "outputId": "7d15da86-4bc8-48b4-ad48-6e95632c8ebf"
      },
      "source": [
        "# Snowball Stemmer => a bit better than PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(language='english')\n",
        "tokens = ['compute', 'computer', 'computed', 'computing']\n",
        "for token in tokens:\n",
        "    print(token + ' --> ' + stemmer.stem(token))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compute --> comput\n",
            "computer --> comput\n",
            "computed --> comput\n",
            "computing --> comput\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF-iQzNg9s9j"
      },
      "source": [
        "#### Lemmatization\n",
        "\n",
        "Lemmatization is a Natural Language Processing technique that proposes to reduce a word to its Lemma, or Canonical Form => called \"dictionary form\" \n",
        "=> https://en.wikipedia.org/wiki/Lemmatisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3AArwZJ7CiM"
      },
      "source": [
        "# Lemmatization function\n",
        "def lemmatize(sentence_list, nlp):\n",
        "    new_norm=[]\n",
        "    print(\"Lemmatizing Sentences\")\n",
        "    for sentence in tqdm(sentence_list):\n",
        "        new_norm.append(lemmatize_text(sentence, nlp).strip())\n",
        "    return new_norm\n",
        "\n",
        "# Lemmatization is language dependent hence we need to pass Spacy \"nlp\" object \n",
        "def lemmatize_text(sentence, nlp):\n",
        "    sent = \"\"\n",
        "    doc = nlp(sentence)\n",
        "    for token in doc:\n",
        "        if '@' in token.text:\n",
        "            sent+=\" @MENTION\"\n",
        "        elif '#' in token.text:\n",
        "            sent+= \" #HASHTAG\"\n",
        "        else:\n",
        "            sent+=\" \"+token.lemma_\n",
        "    return sent"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "oICt_J2G8PUb",
        "outputId": "bf237b25-65f7-4b0b-9de1-170956a3ee07"
      },
      "source": [
        "lemmatize_text(u\"Place red apples on top of two boxes\", nlp)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' place red apple on top of two box'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "D6uJtAdC8HRR",
        "outputId": "fe46a1ee-83c8-4b17-859a-4ff063c4f44d"
      },
      "source": [
        "lemmatize_text(u\"I went home from his parents\", nlp)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' -PRON- go home from -PRON- parent'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6MUA_B_-yUf"
      },
      "source": [
        "#### Spelling correction\n",
        "\n",
        "Correct the spelling of a word :-)\n",
        "\n",
        "We will use **SymSpell** spelling correction!\n",
        "\n",
        "Spelling correction & Fuzzy search: **1 million times faster through Symmetric Delete spelling correction algorithm**\n",
        "\n",
        "The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster (than the standard approach with deletes + transposes + replaces + inserts) and language independent.\n",
        "\n",
        "https://github.com/wolfgarbe/SymSpell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-BXrHxk-447",
        "outputId": "76fe6b56-60ad-443c-c3a1-f1e481b5b8af"
      },
      "source": [
        "# Symspell \n",
        "!pip install symspellpy"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: symspellpy in /usr/local/lib/python3.6/dist-packages (6.7.0)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcWw11DlIgX3"
      },
      "source": [
        "from symspellpy.symspellpy import SymSpell, Verbosity\n",
        "from tqdm.notebook import tqdm\n",
        "import re, string, json\n",
        "from itertools import islice\n",
        "import pkg_resources\n",
        "\n",
        "max_edit_distance_dictionary= 3 \n",
        "prefix_length = 4\n",
        "\n",
        "spellchecker = SymSpell(max_edit_distance_dictionary, prefix_length)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS1mHRgKItH_",
        "outputId": "f8a198d0-1327-4004-98bc-7d7d258f6007"
      },
      "source": [
        "# Load word frequency dictionary \n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "spellchecker.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "\n",
        "# Print out first 5 elements to show dictionary is successfully loaded\n",
        "print(list(islice(spellchecker.words.items(), 5)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 23135851162), ('of', 13151942776), ('and', 12997637966), ('to', 12136980858), ('a', 9081174698)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhY0ZdH5J5GM"
      },
      "source": [
        "**You can also create your own dictionary from plain text file** \n",
        "\n",
        "Input text file:\n",
        "`abc abc-def abc_def abc'def abc qwe qwe1 1qwe q1we 1234 1234`\n",
        "\n",
        "You can create a dictionary from the file using create_dictionary() as in https://symspellpy.readthedocs.io/en/latest/examples/dictionary.html:\n",
        "\n",
        "```\n",
        "from symspellpy import SymSpell\n",
        "\n",
        "sym_spell = SymSpell()\n",
        "corpus_path = <path/to/plain/text/file>\n",
        "sym_spell.create_dictionary(corpus_path)\n",
        "\n",
        "print(sym_spell.words)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RS7rMSM_O76"
      },
      "source": [
        "# Inspired by article https://towardsdatascience.com/text-normalization-7ecc8e084e31\n",
        "# and examples taken from https://colab.research.google.com/drive/1U_C_4wAtlWQdaA84yVwHUCdkvQWEd7r9 \n",
        "\n",
        "def _reduce_exaggerations(text):\n",
        "    # Auxiliary function to help with exxagerated words.\n",
        "    # Examples: woooooords -> words,  yaaaaaaaaaaaaaaay -> yay\n",
        "    correction = str(text)\n",
        "    return re.sub(r'([\\w])\\1+', r'\\1', correction)\n",
        "\n",
        "def is_numeric(text):\n",
        "    for char in text:\n",
        "        if not (char in \"0123456789\" or char in \",%.$\"):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def spell_correction(sentence_list, \n",
        "                     max_edit_distance_dictionary= 3,\n",
        "                     prefix_length = 4):\n",
        "    # Load word frequency dictionary \n",
        "    dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "    spellchecker.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "    norm_sents = []\n",
        "    print(\"Spell correcting\")\n",
        "    for sentence in tqdm(sentence_list):\n",
        "        norm_sents.append(spell_correction_text(sentence,\n",
        "                                                spellchecker,\n",
        "                                                max_edit_distance_dictionary,\n",
        "                                                prefix_length))\n",
        "    return norm_sents\n",
        "\n",
        "def spell_correction_text(text, \n",
        "                          spellchecker, \n",
        "                          max_edit_distance_dictionary= 3,\n",
        "                          prefix_length = 4):\n",
        "    \"\"\"\n",
        "    This function does very simple spell correction normalization using \n",
        "    pyspellchecker module. It works over a tokenized sentence and only the \n",
        "    token representations are changed.\n",
        "    \"\"\"\n",
        "    if len(text) < 1:\n",
        "        return \"\"\n",
        "    #Spell checker config\n",
        "    max_edit_distance_lookup = 2\n",
        "    suggestion_verbosity = Verbosity.TOP # TOP, CLOSEST, ALL\n",
        "    #End of Spell checker config\n",
        "    token_list = text.split()\n",
        "    for word_pos in range(len(token_list)):\n",
        "        word = token_list[word_pos]\n",
        "        if word is None:\n",
        "            token_list[word_pos] = \"\"\n",
        "            continue\n",
        "        if not '\\n' in word and word not in string.punctuation and not is_numeric(word) and not (word.lower() in spellchecker.words.keys()):\n",
        "            suggestions = spellchecker.lookup(word.lower(), suggestion_verbosity, max_edit_distance_lookup)\n",
        "            #Checks first uppercase to conserve the case.\n",
        "            upperfirst = word[0].isupper()\n",
        "            #Checks for correction suggestions.\n",
        "            if len(suggestions) > 0:\n",
        "                correction = suggestions[0].term\n",
        "                replacement = correction\n",
        "            #We call our _reduce_exaggerations function if no suggestion is found. Maybe there are repeated chars.\n",
        "            else:\n",
        "                replacement = _reduce_exaggerations(word)\n",
        "            #Takes the case back to the word.\n",
        "            if upperfirst:\n",
        "                replacement = replacement[0].upper()+replacement[1:]\n",
        "            word = replacement\n",
        "            token_list[word_pos] = word\n",
        "    return \" \".join(token_list).strip()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y7pPMfv_0DP",
        "outputId": "29604ccf-281b-463d-d04b-b7ab70726255"
      },
      "source": [
        "sentence_original=\"in te dhird qarter oflast jear he had elarned aoubt namials\"\n",
        "sentence_corrected = spell_correction_text(sentence_original,\n",
        "                                           spellchecker, \n",
        "                                           max_edit_distance_dictionary= 10,\n",
        "                                           prefix_length = 1)\n",
        "print(\"Original:  \" + sentence_original)\n",
        "print(\"Corrected: \" + sentence_corrected)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  in te dhird qarter oflast jear he had elarned aoubt namials\n",
            "Corrected: in the third quarter oblast year he had learned doubt animals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1beVZDnoCHh"
      },
      "source": [
        "### Fifth step: **Part**-of-speech tagging\n",
        "\n",
        "You can also obtain the part of speech tag for each word.  Common parts of speech include nouns, verbs, pronouns, and adjectives. => see here a full list of https://spacy.io/api/annotation \n",
        "\n",
        "Examples of Universal Part-of-speech tags:\n",
        "* ADJ\tadjective\tbig, old, green, incomprehensible, first\n",
        "* ADP\tadposition\tin, to, during\n",
        "* ADV\tadverb\tvery, tomorrow, down, where, there\n",
        "* AUX\tauxiliary\tis, has (done), will (do), should (do)\n",
        "* CONJ\tconjunction\tand, or, but\n",
        "* CCONJ\tcoordinating conjunction\tand, or, but\n",
        "* DET\tdeterminer\ta, an, the\n",
        "* INTJ\tinterjection\tpsst, ouch, bravo, hello\n",
        "* NOUN\tnoun\tgirl, cat, tree, air, beauty\n",
        "* NUM\tnumeral\t1, 2017, one, seventy-seven, IV, MMXIV\n",
        "* PART\tparticle\t‚Äôs, not,\n",
        "* PRON\tpronoun\tI, you, he, she, myself, themselves, somebody\n",
        "* PROPN\tproper noun\tMary, John, London, NATO, HBO\n",
        "* PUNCT\tpunctuation\t., (, ), ?\n",
        "* SCONJ\tsubordinating conjunction\tif, while, that\n",
        "* SYM\tsymbol\t$, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù\n",
        "* VERB\tverb\trun, runs, running, eat, ate, eating\n",
        "* X\tother\tsfpksdpsxmsa\n",
        "* SPACE\tspace\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNXqNQWwuW1u",
        "outputId": "3116fab2-51d6-4902-b72d-58fec092b3d3"
      },
      "source": [
        "doc = nlp(u\"My name is Andreas.\")\n",
        "for word in doc:  \n",
        "    print(word.text,  word.pos_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My DET\n",
            "name NOUN\n",
            "is AUX\n",
            "Andreas PROPN\n",
            ". PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fn1QwI5t0TU",
        "outputId": "4dac6540-0c8c-4c9b-9b7d-1e7485a76708"
      },
      "source": [
        "doc = nlp(u\"Peter has two cats and one dog!\")\n",
        "for word in doc:  \n",
        "    print(word.text,  word.pos_)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peter PROPN\n",
            "has AUX\n",
            "two NUM\n",
            "cats NOUN\n",
            "and CCONJ\n",
            "one NUM\n",
            "dog NOUN\n",
            "! PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55fJ4EuaN3kk",
        "outputId": "4a462d60-9e54-41a6-980d-49fbd9a8f564"
      },
      "source": [
        "doc = nlp(u\"Peter (peter@coolguy.com, www.github.com/peter) has two cats and 1 dog!\")\n",
        "for word in doc:\n",
        "      if not word.pos_  in (\"PUNCT\", \"CCONJ\"):\n",
        "        print(word.text,  word.pos_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peter PROPN\n",
            "peter@coolguy.com X\n",
            "www.github.com/peter PROPN\n",
            "has AUX\n",
            "two NUM\n",
            "cats NOUN\n",
            "1 NUM\n",
            "dog NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJOEmLH1oCHh"
      },
      "source": [
        "Spacy includes functions to check if parts of a sentence appear to be numbers, acronyms, or other entities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQzowokMoCHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1b20e8-41f7-4e83-e3c4-6d3b83acba13"
      },
      "source": [
        "# Print our Spacy doc\n",
        "doc = nlp(u\"Peter (peter@coolguy.com, https://github.com/peter) has two cats and 1 dog!\")\n",
        "print(f\"---\\n Spacy doc: '{doc}''\")\n",
        "for word in doc:\n",
        "    print(f\"---\\n Word: '{word}''\")\n",
        "    print(f\"'{word}' is like number? {word.like_num}\")\n",
        "    print(f\"'{word}' is like email? {word.like_email}\")\n",
        "    print(f\"'{word}' is like url? {word.like_url}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---\n",
            " Spacy doc: 'Peter (peter@coolguy.com, https://github.com/peter) has two cats and 1 dog!''\n",
            "---\n",
            " Word: 'Peter''\n",
            "'Peter' is like number? False\n",
            "'Peter' is like email? False\n",
            "'Peter' is like url? False\n",
            "---\n",
            " Word: '(''\n",
            "'(' is like number? False\n",
            "'(' is like email? False\n",
            "'(' is like url? False\n",
            "---\n",
            " Word: 'peter@coolguy.com''\n",
            "'peter@coolguy.com' is like number? False\n",
            "'peter@coolguy.com' is like email? True\n",
            "'peter@coolguy.com' is like url? False\n",
            "---\n",
            " Word: ',''\n",
            "',' is like number? False\n",
            "',' is like email? False\n",
            "',' is like url? False\n",
            "---\n",
            " Word: 'https://github.com/peter''\n",
            "'https://github.com/peter' is like number? False\n",
            "'https://github.com/peter' is like email? False\n",
            "'https://github.com/peter' is like url? True\n",
            "---\n",
            " Word: ')''\n",
            "')' is like number? False\n",
            "')' is like email? False\n",
            "')' is like url? False\n",
            "---\n",
            " Word: 'has''\n",
            "'has' is like number? False\n",
            "'has' is like email? False\n",
            "'has' is like url? False\n",
            "---\n",
            " Word: 'two''\n",
            "'two' is like number? True\n",
            "'two' is like email? False\n",
            "'two' is like url? False\n",
            "---\n",
            " Word: 'cats''\n",
            "'cats' is like number? False\n",
            "'cats' is like email? False\n",
            "'cats' is like url? False\n",
            "---\n",
            " Word: 'and''\n",
            "'and' is like number? False\n",
            "'and' is like email? False\n",
            "'and' is like url? False\n",
            "---\n",
            " Word: '1''\n",
            "'1' is like number? True\n",
            "'1' is like email? False\n",
            "'1' is like url? False\n",
            "---\n",
            " Word: 'dog''\n",
            "'dog' is like number? False\n",
            "'dog' is like email? False\n",
            "'dog' is like url? False\n",
            "---\n",
            " Word: '!''\n",
            "'!' is like number? False\n",
            "'!' is like email? False\n",
            "'!' is like url? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGmrBigoP-23"
      },
      "source": [
        "# Named Entity Recognition (NER) with Spacy\n",
        "\n",
        "Named-entity recognition (NER) (also known as (named) entity identification, entity chunking, and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enYzc-M4QQsM"
      },
      "source": [
        "## Rule-based matching\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBq8T4SdQccH",
        "outputId": "4731566e-26e0-43e5-b15e-a99e39909a57"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Import the Matcher\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load a model and create the nlp object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize the matcher with the shared vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "pattern_1 = [\n",
        "    {\"TEXT\": \"iPhone\"}, \n",
        "    {\"POS\": \"NUM\", \"OP\": \"1\"}\n",
        "    # Example\tDescription\n",
        "    # {\"OP\": \"!\"}\tNegation: match 0 times\n",
        "    # {\"OP\": \"?\"}\tOptional: match 0 or 1 times\n",
        "    # {\"OP\": \"+\"}\tMatch 1 or more times\n",
        "    # {\"OP\": \"*\"}\tMatch 0 or more times\n",
        "]\n",
        "pattern_2 = [\n",
        "    {\"POS\": \"NUM\", \"OP\": \"1\"},\n",
        "    {\"TEXT\": \"EUR\"}\n",
        "]\n",
        "\n",
        "matcher.add(\"PATTERN_1\", None, pattern_1)\n",
        "matcher.add(\"PATTERN_2\", None, pattern_2)\n",
        "\n",
        "# Process some text\n",
        "doc = nlp(\"Upcoming iPhone 5 230 EUR with release date is 23.12.2020\")\n",
        "\n",
        "# Call the matcher on the doc\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches\n",
        "for match_id, start, end in matches:\n",
        "    # Get the matched span\n",
        "    matched_span = doc[start:end]\n",
        "    print(matched_span.text)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iPhone 5\n",
            "230 EUR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts-QVEu0QTtb"
      },
      "source": [
        "## Machine-learning based matching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqpbvI4jYM7m"
      },
      "source": [
        "Spacy comes out of the box with pre-train named entity recognition models for organizations, countries, date, money, books, persons, etc. \n",
        "\n",
        "=> pretty cool, have a look https://spacy.io/api/annotation#named-entities \n",
        "```\n",
        "TYPE        DESCRIPTION\n",
        "PERSON      People, including fictional.\n",
        "NORP        Nationalities or religious or political groups.\n",
        "FAC         Buildings, airports, highways, bridges, etc.\n",
        "ORG         Companies, agencies, institutions, etc.\n",
        "GPE         Countries, cities, states.\n",
        "LOC         Non-GPE locations, mountain ranges, bodies of water.\n",
        "PRODUCT     Objects, vehicles, foods, etc. (Not services.)\n",
        "EVENT       Named hurricanes, battles, wars, sports events, etc.\n",
        "WORK_OF_ART Titles of books, songs, etc.\n",
        "LAW         Named documents made into laws.\n",
        "LANGUAGE    Any named language.\n",
        "DATE        Absolute or relative dates or periods.\n",
        "TIME        Times smaller than a day.\n",
        "PERCENT     Percentage, including ‚Äù%‚Äú.\n",
        "MONEY       Monetary values, including unit.\n",
        "QUANTITY    Measurements, as of weight or distance.\n",
        "ORDINAL     ‚Äúfirst‚Äù, ‚Äúsecond‚Äù, etc.\n",
        "CARDINAL    Numerals that do not fall under another type.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2VUcG0AX7py",
        "outputId": "a14c303b-956d-43a1-b355-e1099a204ed5"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple wants to buy two U.K. startup in London headed by German Peter Miller for ‚Ç¨1 billion next year\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple 0 5 ORG\n",
            "two 19 22 CARDINAL\n",
            "U.K. 23 27 GPE\n",
            "London 39 45 GPE\n",
            "German 56 62 NORP\n",
            "Peter Miller 63 75 PERSON\n",
            "‚Ç¨1 billion 80 90 MONEY\n",
            "next year 91 100 DATE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "AJyQxrm-a4BL",
        "outputId": "a907096a-8aee-4337-8d2a-047a3b333f7a"
      },
      "source": [
        "from spacy import displacy\n",
        "from IPython.core.display import display, HTML\n",
        "html = displacy.render(doc, style=\"ent\")\n",
        "display(HTML(html))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " wants to buy \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.K.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " startup in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    London\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " headed by \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    German\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Peter Miller\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ‚Ç¨1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    next year\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "cHg0VWRQaiTv",
        "outputId": "7cc5e5c1-4833-420b-943c-f11986e364c1"
      },
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style='dep', jupyter = True, options = {'distance': 120})\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"188fe8321a404e4788197eae66be0fc8-0\" class=\"displacy\" width=\"2450\" height=\"377.0\" direction=\"ltr\" style=\"max-width: none; height: 377.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">wants</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">buy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">two</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">U.K.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">startup</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">London</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">headed</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">by</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">German</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">Peter</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1610\">Miller</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1610\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1730\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1730\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">‚Ç¨</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1970\">1</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1970\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2090\">billion</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2090\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2210\">next</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2210\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2330\">year</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2330\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-0\" stroke-width=\"2px\" d=\"M70,242.0 C70,182.0 155.0,182.0 155.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,244.0 L62,232.0 78,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-1\" stroke-width=\"2px\" d=\"M310,242.0 C310,182.0 395.0,182.0 395.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M310,244.0 L302,232.0 318,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-2\" stroke-width=\"2px\" d=\"M190,242.0 C190,122.0 400.0,122.0 400.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400.0,244.0 L408.0,232.0 392.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-3\" stroke-width=\"2px\" d=\"M550,242.0 C550,122.0 760.0,122.0 760.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M550,244.0 L542,232.0 558,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-4\" stroke-width=\"2px\" d=\"M670,242.0 C670,182.0 755.0,182.0 755.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M670,244.0 L662,232.0 678,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-5\" stroke-width=\"2px\" d=\"M430,242.0 C430,62.0 765.0,62.0 765.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M765.0,244.0 L773.0,232.0 757.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-6\" stroke-width=\"2px\" d=\"M790,242.0 C790,182.0 875.0,182.0 875.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M875.0,244.0 L883.0,232.0 867.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-7\" stroke-width=\"2px\" d=\"M910,242.0 C910,182.0 995.0,182.0 995.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M995.0,244.0 L1003.0,232.0 987.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-8\" stroke-width=\"2px\" d=\"M790,242.0 C790,62.0 1125.0,62.0 1125.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1125.0,244.0 L1133.0,232.0 1117.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-9\" stroke-width=\"2px\" d=\"M1150,242.0 C1150,182.0 1235.0,182.0 1235.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1235.0,244.0 L1243.0,232.0 1227.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-10\" stroke-width=\"2px\" d=\"M1390,242.0 C1390,122.0 1600.0,122.0 1600.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1390,244.0 L1382,232.0 1398,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-11\" stroke-width=\"2px\" d=\"M1510,242.0 C1510,182.0 1595.0,182.0 1595.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1510,244.0 L1502,232.0 1518,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-12\" stroke-width=\"2px\" d=\"M1270,242.0 C1270,62.0 1605.0,62.0 1605.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1605.0,244.0 L1613.0,232.0 1597.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-13\" stroke-width=\"2px\" d=\"M1150,242.0 C1150,2.0 1730.0,2.0 1730.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1730.0,244.0 L1738.0,232.0 1722.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-14\" stroke-width=\"2px\" d=\"M1870,242.0 C1870,122.0 2080.0,122.0 2080.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1870,244.0 L1862,232.0 1878,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-15\" stroke-width=\"2px\" d=\"M1990,242.0 C1990,182.0 2075.0,182.0 2075.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1990,244.0 L1982,232.0 1998,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-16\" stroke-width=\"2px\" d=\"M1750,242.0 C1750,62.0 2085.0,62.0 2085.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2085.0,244.0 L2093.0,232.0 2077.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-17\" stroke-width=\"2px\" d=\"M2230,242.0 C2230,182.0 2315.0,182.0 2315.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2230,244.0 L2222,232.0 2238,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-188fe8321a404e4788197eae66be0fc8-0-18\" stroke-width=\"2px\" d=\"M2110,242.0 C2110,122.0 2320.0,122.0 2320.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-188fe8321a404e4788197eae66be0fc8-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2320.0,244.0 L2328.0,232.0 2312.0,232.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NtU1HLIaJYU"
      },
      "source": [
        "Spacy allows you also to train your own NER pipeline based on your domain vocabulary e.g. voice user interface, chatbot, voicebot etc. https://spacy.io/api/annotation#named-entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DMGBxIpUNJe"
      },
      "source": [
        "TRAIN_DATA = [('what is the price of polo?', {'entities': [(21, 25, 'PrdName')]}), \n",
        "              ('what is the price of ball?', {'entities': [(21, 25, 'PrdName')]}), \n",
        "              ('what is the price of jegging?', {'entities': [(21, 28, 'PrdName')]}), \n",
        "              ('what is the price of t-shirt?', {'entities': [(21, 28, 'PrdName')]}), \n",
        "              ('what is the price of jeans?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "              ('what is the price of bat?', {'entities': [(21, 24, 'PrdName')]}), \n",
        "              ('what is the price of shirt?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "              ('what is the price of bag?', {'entities': [(21, 24, 'PrdName')]}), \n",
        "              ('what is the price of cup?', {'entities': [(21, 24, 'PrdName')]}), \n",
        "              ('what is the price of jug?', {'entities': [(21, 24, 'PrdName')]}), \n",
        "              ('what is the price of plate?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "              ('what is the price of glass?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "              ('what is the price of moniter?', {'entities': [(21, 28, 'PrdName')]}), \n",
        "              ('what is the price of desktop?', {'entities': [(21, 28, 'PrdName')]}), \n",
        "              ('what is the price of bottle?', {'entities': [(21, 27, 'PrdName')]}), \n",
        "              ('what is the price of mouse?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "              ('what is the price of keyboad?', {'entities': [(21, 28, 'PrdName')]}), \n",
        "              ('what is the price of chair?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "              ('what is the price of table?', {'entities': [(21, 26, 'PrdName')]}), \n",
        "              ('what is the price of watch?', {'entities': [(21, 26, 'PrdName')]})]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl4yyRyqb13B"
      },
      "source": [
        "import random\n",
        "\n",
        "def train_spacy(data, iterations, nlp=spacy.blank('en')) :\n",
        "\n",
        "    # spacy.blank('en') creates blank Language class\n",
        "    training_data = data\n",
        "    # create the built-in pipeline components and add them to the pipeline\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        print(\"Create new NER pipe...\")\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "    else:\n",
        "        print(\"Get exiting NER pipe...\")\n",
        "        ner = nlp.get_pipe(\"ner\")   \n",
        "\n",
        "    # add labels\n",
        "    for _, annotations in training_data:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(iterations):\n",
        "            print(\"Statring iteration \" + str(itn))\n",
        "            random.shuffle(training_data)\n",
        "            losses = {}\n",
        "            for text, annotations in training_data:\n",
        "                nlp.update(\n",
        "                    [text],  # batch of texts\n",
        "                    [annotations],  # batch of annotations\n",
        "                    drop=0.35,  # dropout - make it harder to memorise data\n",
        "                    sgd=optimizer,  # callable to update weights\n",
        "                    losses=losses)\n",
        "            print(losses)\n",
        "    return nlp"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LZ1xRCBcfST",
        "outputId": "092386ed-2dba-46b3-ac05-f9a90d6d375e"
      },
      "source": [
        "# Train our custom spacy model\n",
        "\n",
        "# specify the training data and the number of training iteration\n",
        "training_iterations=40\n",
        "nlp_blank_model = spacy.blank('en') # creates blank Language class\n",
        "nlp = train_spacy(TRAIN_DATA, training_iterations, nlp_blank_model)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create new NER pipe...\n",
            "Statring iteration 0\n",
            "{'ner': 56.68599391818498}\n",
            "Statring iteration 1\n",
            "{'ner': 5.28018560021256}\n",
            "Statring iteration 2\n",
            "{'ner': 2.081231088360586}\n",
            "Statring iteration 3\n",
            "{'ner': 1.9855227574135828}\n",
            "Statring iteration 4\n",
            "{'ner': 1.8048718859922444}\n",
            "Statring iteration 5\n",
            "{'ner': 1.5616133593668349}\n",
            "Statring iteration 6\n",
            "{'ner': 6.320991190412769}\n",
            "Statring iteration 7\n",
            "{'ner': 0.9403462220264008}\n",
            "Statring iteration 8\n",
            "{'ner': 0.9812280102499094}\n",
            "Statring iteration 9\n",
            "{'ner': 2.151801657317973}\n",
            "Statring iteration 10\n",
            "{'ner': 2.440918168532199}\n",
            "Statring iteration 11\n",
            "{'ner': 1.754771351208338}\n",
            "Statring iteration 12\n",
            "{'ner': 2.2679379770854853}\n",
            "Statring iteration 13\n",
            "{'ner': 1.8323523977110472}\n",
            "Statring iteration 14\n",
            "{'ner': 1.2504291374232614}\n",
            "Statring iteration 15\n",
            "{'ner': 0.36129471359205617}\n",
            "Statring iteration 16\n",
            "{'ner': 0.43554425108106193}\n",
            "Statring iteration 17\n",
            "{'ner': 0.1593883594172609}\n",
            "Statring iteration 18\n",
            "{'ner': 0.03863711543412125}\n",
            "Statring iteration 19\n",
            "{'ner': 0.033930938921391825}\n",
            "Statring iteration 20\n",
            "{'ner': 0.00010252997765326807}\n",
            "Statring iteration 21\n",
            "{'ner': 6.527480436880435e-06}\n",
            "Statring iteration 22\n",
            "{'ner': 0.0001935598348798414}\n",
            "Statring iteration 23\n",
            "{'ner': 2.5511817194964863e-06}\n",
            "Statring iteration 24\n",
            "{'ner': 8.718173197647505e-07}\n",
            "Statring iteration 25\n",
            "{'ner': 9.12010296883022e-06}\n",
            "Statring iteration 26\n",
            "{'ner': 6.930666534195776e-07}\n",
            "Statring iteration 27\n",
            "{'ner': 2.0881725552222451e-07}\n",
            "Statring iteration 28\n",
            "{'ner': 4.483513073200587e-07}\n",
            "Statring iteration 29\n",
            "{'ner': 2.3506276016874066e-07}\n",
            "Statring iteration 30\n",
            "{'ner': 2.3893588032635195e-05}\n",
            "Statring iteration 31\n",
            "{'ner': 3.81098257870759e-05}\n",
            "Statring iteration 32\n",
            "{'ner': 9.152010963962165e-10}\n",
            "Statring iteration 33\n",
            "{'ner': 4.489886525058686e-07}\n",
            "Statring iteration 34\n",
            "{'ner': 1.1241671331001497e-07}\n",
            "Statring iteration 35\n",
            "{'ner': 6.776715626896256e-07}\n",
            "Statring iteration 36\n",
            "{'ner': 8.107355127199358e-07}\n",
            "Statring iteration 37\n",
            "{'ner': 5.1168382208030375e-09}\n",
            "Statring iteration 38\n",
            "{'ner': 2.2470551734290442e-07}\n",
            "Statring iteration 39\n",
            "{'ner': 4.685516790894837e-09}\n",
            "Statring iteration 40\n",
            "{'ner': 1.7093362760857995e-05}\n",
            "Statring iteration 41\n",
            "{'ner': 7.892873145681273e-08}\n",
            "Statring iteration 42\n",
            "{'ner': 4.259389531306948e-08}\n",
            "Statring iteration 43\n",
            "{'ner': 4.477586619290189e-06}\n",
            "Statring iteration 44\n",
            "{'ner': 1.7309892790229325e-07}\n",
            "Statring iteration 45\n",
            "{'ner': 1.4983842922685606e-06}\n",
            "Statring iteration 46\n",
            "{'ner': 4.319323910545399e-08}\n",
            "Statring iteration 47\n",
            "{'ner': 2.952331078708671e-08}\n",
            "Statring iteration 48\n",
            "{'ner': 6.09871126482082e-10}\n",
            "Statring iteration 49\n",
            "{'ner': 7.511566108709051e-09}\n",
            "Statring iteration 50\n",
            "{'ner': 6.252424468676351e-08}\n",
            "Statring iteration 51\n",
            "{'ner': 1.42829852511432e-08}\n",
            "Statring iteration 52\n",
            "{'ner': 2.5951484449053145e-08}\n",
            "Statring iteration 53\n",
            "{'ner': 0.10325541215662341}\n",
            "Statring iteration 54\n",
            "{'ner': 0.07692890913621696}\n",
            "Statring iteration 55\n",
            "{'ner': 5.331396419651127e-08}\n",
            "Statring iteration 56\n",
            "{'ner': 0.4618175945781836}\n",
            "Statring iteration 57\n",
            "{'ner': 1.36609162308773e-05}\n",
            "Statring iteration 58\n",
            "{'ner': 4.450054391738225}\n",
            "Statring iteration 59\n",
            "{'ner': 2.316022405324376}\n",
            "Statring iteration 60\n",
            "{'ner': 9.925152394356891e-05}\n",
            "Statring iteration 61\n",
            "{'ner': 6.822434810652191e-07}\n",
            "Statring iteration 62\n",
            "{'ner': 1.0014950359642776e-05}\n",
            "Statring iteration 63\n",
            "{'ner': 4.340201973282672e-06}\n",
            "Statring iteration 64\n",
            "{'ner': 1.5168097249761835e-05}\n",
            "Statring iteration 65\n",
            "{'ner': 4.465040589176789e-07}\n",
            "Statring iteration 66\n",
            "{'ner': 1.6726910047118017e-08}\n",
            "Statring iteration 67\n",
            "{'ner': 3.870092062434875e-10}\n",
            "Statring iteration 68\n",
            "{'ner': 2.4525999816030026e-05}\n",
            "Statring iteration 69\n",
            "{'ner': 1.6517491846467645e-09}\n",
            "Statring iteration 70\n",
            "{'ner': 2.7718824244817947e-12}\n",
            "Statring iteration 71\n",
            "{'ner': 3.4403290798564597e-07}\n",
            "Statring iteration 72\n",
            "{'ner': 2.7305310732737204e-09}\n",
            "Statring iteration 73\n",
            "{'ner': 1.963144667877928e-11}\n",
            "Statring iteration 74\n",
            "{'ner': 2.55141617440189e-11}\n",
            "Statring iteration 75\n",
            "{'ner': 8.805056446444387e-11}\n",
            "Statring iteration 76\n",
            "{'ner': 2.379343105434912e-06}\n",
            "Statring iteration 77\n",
            "{'ner': 2.4268189049453523e-10}\n",
            "Statring iteration 78\n",
            "{'ner': 3.292305502970274e-10}\n",
            "Statring iteration 79\n",
            "{'ner': 8.052326410205715e-11}\n",
            "Statring iteration 80\n",
            "{'ner': 5.327294553750952e-10}\n",
            "Statring iteration 81\n",
            "{'ner': 6.8130098893091755e-09}\n",
            "Statring iteration 82\n",
            "{'ner': 3.9662002107820993e-10}\n",
            "Statring iteration 83\n",
            "{'ner': 1.2825015232863226e-11}\n",
            "Statring iteration 84\n",
            "{'ner': 2.4447867331406494e-10}\n",
            "Statring iteration 85\n",
            "{'ner': 2.3929775309290058e-08}\n",
            "Statring iteration 86\n",
            "{'ner': 2.182986372654663e-06}\n",
            "Statring iteration 87\n",
            "{'ner': 4.182407230308005e-11}\n",
            "Statring iteration 88\n",
            "{'ner': 3.627406311927095e-12}\n",
            "Statring iteration 89\n",
            "{'ner': 2.8502797072256163e-11}\n",
            "Statring iteration 90\n",
            "{'ner': 2.9441898227275085e-09}\n",
            "Statring iteration 91\n",
            "{'ner': 2.1174156202787642e-10}\n",
            "Statring iteration 92\n",
            "{'ner': 1.2357008586365901e-12}\n",
            "Statring iteration 93\n",
            "{'ner': 1.987877136208403e-10}\n",
            "Statring iteration 94\n",
            "{'ner': 8.95358382834469e-09}\n",
            "Statring iteration 95\n",
            "{'ner': 2.750568067074356e-08}\n",
            "Statring iteration 96\n",
            "{'ner': 1.7219588505513516e-10}\n",
            "Statring iteration 97\n",
            "{'ner': 7.452900907344843e-09}\n",
            "Statring iteration 98\n",
            "{'ner': 1.5071533356896884e-12}\n",
            "Statring iteration 99\n",
            "{'ner': 6.376293835676956e-10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cp5OKiwmPec",
        "outputId": "f0773a31-2525-4103-e790-527d8d95159b"
      },
      "source": [
        "# Test your model with a text which is very similar \n",
        "test_text = \"u'what is the price of a bat?\"\n",
        "doc = nlp(test_text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a bat 23 28 PrdName\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z-6RktqeDzH",
        "outputId": "89ce5ee1-4e90-468b-f071-c7746bd8fa6b"
      },
      "source": [
        "#Test your text\n",
        "test_text = \"u'price of bat?\"\n",
        "doc = nlp(test_text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bat 11 14 PrdName\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAz_qYaImksa",
        "outputId": "4d898d0e-a1d6-4e2e-c093-a8327051b815"
      },
      "source": [
        "# Test your model with variations of text \n",
        "test_text = \"u'what is the price of a bat and a pollo?\"\n",
        "# test_text = \"u'what is the price of one bat and two pollo?\"\n",
        "# test_text = \"u'price bat and three pollo?\"\n",
        "# test_text = \"u'price of bat and three pollo?\"\n",
        "\n",
        "doc = nlp(test_text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a bat and a pollo 23 40 PrdName\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2lIHdaOb4Kx"
      },
      "source": [
        "# Save your trained model to disk and load it again\n",
        "\n",
        "modelfile =\"model_file_1.ner.spacy\"\n",
        "# save to disk\n",
        "nlp.to_disk(modelfile)\n",
        "\n",
        "# load model from disk\n",
        "nlp = spacy.load(modelfile)"
      ],
      "execution_count": 38,
      "outputs": []
    }
  ]
}
