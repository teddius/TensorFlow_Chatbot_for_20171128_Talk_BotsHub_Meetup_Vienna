{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "python_chatbot_example_with_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teddius/TensorFlow_Chatbot_for_20171128_Talk_BotsHub_Meetup_Vienna/blob/master/python_chatbot_example_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQUCHAoB_Qe2"
      },
      "source": [
        "##########################################################################################\n",
        "# \"How to make a simple contextualized chatbot with tensorflow, keras, nltk and sklearn\"\n",
        "# \n",
        "#  by Andreas S. Rath <andreas.rath@ondewo.com> \n",
        "#  Github name: teddius\n",
        "#  Github source code: http://bit.ly/tfcb17ondewo\n",
        "#\n",
        "#  Inspired by chatbotsmagazine article which was based on \"tflearn\" and is available at \n",
        "#  https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077\n",
        "##########################################################################################"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DhznYCP_Qe9"
      },
      "source": [
        "\n",
        "######################################################################\n",
        "# basic things we need for python processing and google colab\n",
        "######################################################################\n",
        "\n",
        "import random\n",
        "import base64\n",
        "import requests\n",
        "import numpy as np\n",
        "import json\n",
        "from google.colab import files"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWhXEj5lCgkQ",
        "outputId": "80767dbf-99aa-4475-d273-29b374d81d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "######################################################################\n",
        "# Things we need for NLP\n",
        "######################################################################\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer() # english stemmer"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbLHEGq8CjkW",
        "outputId": "c3be28cb-2b03-4274-e691-22106d2c4c80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "######################################################################\n",
        "# things we need for Tensorflow\n",
        "######################################################################\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from keras import metrics, optimizers\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "from keras.layers import Dense, Flatten, Conv1D, Embedding, MaxPooling1D, Dropout\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyDq6YTLAknm",
        "outputId": "81e60c0b-3f5a-4125-9c02-f02cbeaa4661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_url = \"https://raw.githubusercontent.com/teddius/TensorFlow_Chatbot_for_20171128_Talk_BotsHub_Meetup_Vienna/master/intents.json\"\n",
        "req = requests.get(data_url)\n",
        "intent_json = req.text\n",
        "print(intent_json)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"intents\": [\n",
            "        {\n",
            "         \"tag\": \"greeting\",\n",
            "         \"patterns\": [\"Hi\", \"Hey\", \"Ho\", \"What's up\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\"],\n",
            "         \"responses\": [\"Hello, thanks for visiting\", \"Good to see you again\", \"Hi there, how can I help?\"],\n",
            "         \"context_set\": \"\"\n",
            "        },\n",
            "        {\n",
            "         \"tag\": \"goodbye\",\n",
            "         \"patterns\": [\"Bye\", \"Bye bye\", \"Ciao\",\"See you later\", \"Goodbye\"],\n",
            "         \"responses\": [\"Happy to talk to you later!\",\"Thanks for showing up!\", \"Bye! Looking forward to seeing you again soon!\"]\n",
            "        },\n",
            "        {\n",
            "         \"tag\": \"thanks\",\n",
            "         \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Perfect, thank you so much\"],\n",
            "         \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\"]\n",
            "        },\n",
            "        {\n",
            "         \"tag\": \"hours\",\n",
            "         \"patterns\": [\"What hours are you open?\", \"What are your hours?\", \"When are you open?\", \"Opening times?\" ],\n",
            "         \"responses\": [\"We're open every day 9am-9pm\", \"Our hours are 9am-9pm every day\"]\n",
            "        },\n",
            "        {\n",
            "         \"tag\": \"mopeds\",\n",
            "         \"patterns\": [\"Which mopeds do you have?\", \"What kinds of mopeds are there?\", \"What do you rent?\" ],\n",
            "         \"responses\": [\"We rent Yamaha, Piaggio and Vespa mopeds\", \"We have Piaggio, Vespa and Yamaha mopeds\"]\n",
            "        },\n",
            "        {\n",
            "         \"tag\": \"payments\",\n",
            "         \"patterns\": [\"Do you take credit cards?\", \"Do you accept Mastercard?\", \"Are you cash only?\", \"Which credit cards do you accept\" ],\n",
            "         \"responses\": [\"We accept VISA, Mastercard and AMEX\", \"We accept most major credit cards\"]\n",
            "        },\n",
            "        {\n",
            "         \"tag\": \"opentoday\",\n",
            "         \"patterns\": [\"Are you open today?\", \"When do you open today?\", \"At what times are you open today?\", \"What are you opening times today?\"],\n",
            "         \"responses\": [\"We're open every day from 9am-9pm\", \"Our hours are 9am-9pm every day\"]\n",
            "        },\n",
            "        {\n",
            "         \"tag\": \"rental\",\n",
            "         \"patterns\": [\"Can we rent a moped?\", \"I'd like to rent a moped\", \"How does this work?\" ],\n",
            "         \"responses\": [\"Are you looking to rent today or later this week?\"],\n",
            "         \"context_set\": \"rentalday\"\n",
            "        },\n",
            "        {\n",
            "         \"tag\": \"today\",\n",
            "         \"patterns\": [\"today\", \"rent today\", \"I want to rent today\"],\n",
            "         \"responses\": [\"For rentals today please call 1-800-MYMOPED\", \"Same-day rentals please call 1-800-MYMOPED\"],\n",
            "         \"context_filter\": \"rentalday\"\n",
            "        }\n",
            "   ]\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1VaGjMb_Qe_",
        "outputId": "2044f60e-fe66-47b9-aabb-ade45a7af0ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "######################################################################\n",
        "# Import our chat-bot intents file\n",
        "######################################################################\n",
        "\n",
        "intents = json.loads(intent_json)\n",
        "print(intents)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'Ho', \"What's up\", 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hello, thanks for visiting', 'Good to see you again', 'Hi there, how can I help?'], 'context_set': ''}, {'tag': 'goodbye', 'patterns': ['Bye', 'Bye bye', 'Ciao', 'See you later', 'Goodbye'], 'responses': ['Happy to talk to you later!', 'Thanks for showing up!', 'Bye! Looking forward to seeing you again soon!']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", 'Perfect, thank you so much'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'hours', 'patterns': ['What hours are you open?', 'What are your hours?', 'When are you open?', 'Opening times?'], 'responses': [\"We're open every day 9am-9pm\", 'Our hours are 9am-9pm every day']}, {'tag': 'mopeds', 'patterns': ['Which mopeds do you have?', 'What kinds of mopeds are there?', 'What do you rent?'], 'responses': ['We rent Yamaha, Piaggio and Vespa mopeds', 'We have Piaggio, Vespa and Yamaha mopeds']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Are you cash only?', 'Which credit cards do you accept'], 'responses': ['We accept VISA, Mastercard and AMEX', 'We accept most major credit cards']}, {'tag': 'opentoday', 'patterns': ['Are you open today?', 'When do you open today?', 'At what times are you open today?', 'What are you opening times today?'], 'responses': [\"We're open every day from 9am-9pm\", 'Our hours are 9am-9pm every day']}, {'tag': 'rental', 'patterns': ['Can we rent a moped?', \"I'd like to rent a moped\", 'How does this work?'], 'responses': ['Are you looking to rent today or later this week?'], 'context_set': 'rentalday'}, {'tag': 'today', 'patterns': ['today', 'rent today', 'I want to rent today'], 'responses': ['For rentals today please call 1-800-MYMOPED', 'Same-day rentals please call 1-800-MYMOPED'], 'context_filter': 'rentalday'}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAAIxLJg_QfB",
        "outputId": "680ee944-c2c3-487a-9ea6-14890fdcd187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "######################################################################\n",
        "# Let's start to build our training data\n",
        "######################################################################\n",
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?']\n",
        "\n",
        "# loop through each sentence in our intents patterns\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        \n",
        "        # tokenize each word in the sentence\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "      \n",
        "        # add to our words list\n",
        "        words.extend(w)\n",
        "        \n",
        "        # add to documents in our corpus\n",
        "        documents.append((w, intent['tag']))\n",
        "        \n",
        "        # add to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "\n",
        "# stem and lower each word and remove duplicates\n",
        "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "# remove duplicates\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print('------------------------------------------------------')\n",
        "print('-------------  Summary -------------------------------')\n",
        "print('------------------------------------------------------')\n",
        "print('')\n",
        "print(len(classes), \"classes\\n\", classes)\n",
        "print('')\n",
        "print('------------------------------------------------------')\n",
        "print('')\n",
        "print(len(words), \"words\\n\", words)\n",
        "print('')\n",
        "print('------------------------------------------------------')\n",
        "print('')\n",
        "print(len(documents), \"documents\\n\", documents)\n",
        "print('')\n",
        "print('------------------------------------------------------')\n",
        "print('')\n",
        "print(len(words), \"unique stemmed words\\n\", words)\n",
        "print('')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------\n",
            "-------------  Summary -------------------------------\n",
            "------------------------------------------------------\n",
            "\n",
            "9 classes\n",
            " ['goodbye', 'greeting', 'hours', 'mopeds', 'opentoday', 'payments', 'rental', 'thanks', 'today']\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "59 words\n",
            " [\"'d\", \"'s\", ',', 'a', 'acceiv', 'anyon', 'ar', 'at', 'bye', 'can', 'card', 'cash', 'ciao', 'credit', 'day', 'do', 'doe', 'good', 'goodby', 'hav', 'hello', 'help', 'hey', 'hi', 'ho', 'hour', 'how', 'i', 'is', 'kind', 'lat', 'lik', 'mastercard', 'mop', 'much', 'of', 'on', 'op', 'perfect', 'rent', 'see', 'so', 'tak', 'thank', 'that', 'ther', 'thi', 'tim', 'to', 'today', 'up', 'want', 'we', 'what', 'when', 'which', 'work', 'yo', 'you']\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "38 documents\n",
            " [(['Hi'], 'greeting'), (['Hey'], 'greeting'), (['Ho'], 'greeting'), (['What', \"'s\", 'up'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['Bye'], 'goodbye'), (['Bye', 'bye'], 'goodbye'), (['Ciao'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['Perfect', ',', 'thank', 'you', 'so', 'much'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['Opening', 'times', '?'], 'hours'), (['Which', 'mopeds', 'do', 'you', 'have', '?'], 'mopeds'), (['What', 'kinds', 'of', 'mopeds', 'are', 'there', '?'], 'mopeds'), (['What', 'do', 'you', 'rent', '?'], 'mopeds'), (['Do', 'you', 'take', 'credit', 'cards', '?'], 'payments'), (['Do', 'you', 'accept', 'Mastercard', '?'], 'payments'), (['Are', 'you', 'cash', 'only', '?'], 'payments'), (['Which', 'credit', 'cards', 'do', 'you', 'accept'], 'payments'), (['Are', 'you', 'open', 'today', '?'], 'opentoday'), (['When', 'do', 'you', 'open', 'today', '?'], 'opentoday'), (['At', 'what', 'times', 'are', 'you', 'open', 'today', '?'], 'opentoday'), (['What', 'are', 'you', 'opening', 'times', 'today', '?'], 'opentoday'), (['Can', 'we', 'rent', 'a', 'moped', '?'], 'rental'), (['I', \"'d\", 'like', 'to', 'rent', 'a', 'moped'], 'rental'), (['How', 'does', 'this', 'work', '?'], 'rental'), (['today'], 'today'), (['rent', 'today'], 'today'), (['I', 'want', 'to', 'rent', 'today'], 'today')]\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "59 unique stemmed words\n",
            " [\"'d\", \"'s\", ',', 'a', 'acceiv', 'anyon', 'ar', 'at', 'bye', 'can', 'card', 'cash', 'ciao', 'credit', 'day', 'do', 'doe', 'good', 'goodby', 'hav', 'hello', 'help', 'hey', 'hi', 'ho', 'hour', 'how', 'i', 'is', 'kind', 'lat', 'lik', 'mastercard', 'mop', 'much', 'of', 'on', 'op', 'perfect', 'rent', 'see', 'so', 'tak', 'thank', 'that', 'ther', 'thi', 'tim', 'to', 'today', 'up', 'want', 'we', 'what', 'when', 'which', 'work', 'yo', 'you']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yRnTr7vs_QfD",
        "outputId": "c3451967-4eab-4609-b116-374965bd948d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create our training data\n",
        "training = []\n",
        "output = []\n",
        "# create an empty array for our output\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "# training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "    # initialize our bag of words\n",
        "    bag = []\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "    # stem each word\n",
        "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
        "    # create our bag of words array\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "    # output is a '0' for each tag and '1' for current tag\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "    training.append([bag, output_row])\n",
        "    \n",
        "# print('training: ' + str(training))\n",
        "\n",
        "# shuffle our features and turn into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "# create train and test lists\n",
        "X = list(training[:, 0])\n",
        "y = list(training[:, 1])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=32, shuffle=True)\n",
        "\n",
        "print('------------------------------------------------------')\n",
        "print('-------------  Summary -------------------------------')\n",
        "print('------------------------------------------------------')\n",
        "print('')\n",
        "print('Total elements in X: ' + str(len(X)) + ' consisting of') \n",
        "print('elements in X_train: ' + str(len(X_train)) + ' and X_test: ' + str(len(X_test)))\n",
        "print('')\n",
        "print('Total elements in y (labels): ' + str(len(y)) + ' consisting of') \n",
        "print('elements in y_train: ' + str(len(y_train)) + ' and y_test: ' + str(len(y_test)))\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------\n",
            "-------------  Summary -------------------------------\n",
            "------------------------------------------------------\n",
            "\n",
            "Total elements in X: 38 consisting of\n",
            "elements in X_train: 28 and X_test: 10\n",
            "\n",
            "Total elements in y (labels): 38 consisting of\n",
            "elements in y_train: 28 and y_test: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOXPu_6S_QfF",
        "outputId": "79f5efcd-180e-4ec2-d58f-673217755c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('------------------------------------------------------')\n",
        "print('----- Let us look a specific training example --------')\n",
        "print('------------------------------------------------------')\n",
        "print('X_train[0] (bag of word references):', X_train[0])\n",
        "print('------------------------------------------------------')\n",
        "print('y_train[0] (class label):', y_train[0])\n",
        "print('------------------------------------------------------')\n",
        "print('All class labels:', classes)\n",
        "print('------------------------------------------------------')\n",
        "print('Our training example class label at index classes[' + str(y_train[0].index(1))+ ']=',\n",
        "      classes[y_train[0].index(1)])  # TODO show clas"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------\n",
            "----- Let us look a specific training example --------\n",
            "------------------------------------------------------\n",
            "X_train[0] (bag of word references): [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "------------------------------------------------------\n",
            "y_train[0] (class label): [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------------------------------\n",
            "All class labels: ['goodbye', 'greeting', 'hours', 'mopeds', 'opentoday', 'payments', 'rental', 'thanks', 'today']\n",
            "------------------------------------------------------\n",
            "Our training example class label at index classes[2]= hours\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BQEr4O93_QfG",
        "outputId": "504ce8cf-03d7-4065-c082-397fedb58776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "####################################################################################\n",
        "# Build a very simple neural network\n",
        "####################################################################################\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation=\"relu\",input_dim=(np.array(X_train).shape[1])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(classes), activation='softmax'))\n",
        "\n",
        "# metrics\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.1, decay=0.005)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=adam,\n",
        "                  metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "####################################################################################\n",
        "# OPTIONAL for playing around you could add the following layers (watch out to \n",
        "# transform to correct shape)\n",
        "# \n",
        "# model.add(Embedding(len(words), embedding_vector_length))\n",
        "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "####################################################################################"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               6000      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 9)                 459       \n",
            "=================================================================\n",
            "Total params: 11,509\n",
            "Trainable params: 11,509\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUwtFR3I_QfI",
        "outputId": "c2de259e-d683-4098-d62c-901f63b4391b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Callbacks for the evaluation of the model\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs/')\n",
        "checkpoint = ModelCheckpoint('./weights-improvement-{epoch:02d}-{loss:.4f}.hdf5',\n",
        "                             monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "#callbacks_list = [checkpoint, tensorboard_callback, early_stop]\n",
        "callbacks_list = [tensorboard_callback, early_stop]\n",
        "\n",
        "nr_of_epoches=100\n",
        "batch_size=32\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=nr_of_epoches,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 2.2338 - accuracy: 0.1429 - val_loss: 2.3772 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.8512 - accuracy: 0.3214 - val_loss: 3.1465 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.6304 - accuracy: 0.5000 - val_loss: 1.6895 - val_accuracy: 0.4000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.7348 - accuracy: 0.6786 - val_loss: 1.9537 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4234 - accuracy: 0.8214 - val_loss: 1.8612 - val_accuracy: 0.6000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2487 - accuracy: 0.8571 - val_loss: 2.1075 - val_accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0709 - accuracy: 0.9643 - val_loss: 2.5745 - val_accuracy: 0.6000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3663 - accuracy: 0.8571 - val_loss: 3.2795 - val_accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 3.9774 - val_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0791 - accuracy: 0.9643 - val_loss: 4.5740 - val_accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2834 - accuracy: 0.9643 - val_loss: 4.9411 - val_accuracy: 0.6000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.3211 - val_accuracy: 0.6000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6552 - accuracy: 0.9643 - val_loss: 5.8405 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "hRcKZuB7_QfK",
        "outputId": "38b9a88d-3ac5-4be5-edf0-c7cd185dc467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#############################################################\n",
        "# Let's have a look at a single test example from X_test \n",
        "#############################################################\n",
        "print('')\n",
        "print('X_test[0] in total looks like:\\n\\n', X_test[0])\n",
        "print('')\n",
        "print('------------------------------------------------------')\n",
        "print('')\n",
        "print('X_test[0] has the class index stored at y_test[0] with the label: classes[' + str(y_test[0].index(1))+ ']=',\n",
        "      classes[y_test[0].index(1)]) \n",
        "print('')\n",
        "print('------------------------------------------------------')\n",
        "print('')\n",
        "prediction = model.predict(np.array([X_test[0]]))\n",
        "print('Total \"raw\" prediction for all classes looks like:\\n\\n', prediction)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "X_test[0] in total looks like:\n",
            "\n",
            " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "X_test[0] has the class index stored at y_test[0] with the label: classes[0]= goodbye\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "Total \"raw\" prediction for all classes looks like:\n",
            "\n",
            " [[9.9984229e-01 9.8767174e-05 2.7909548e-06 5.5856111e-05 3.7807500e-11\n",
            "  1.6927972e-07 5.0907464e-12 4.0597737e-08 6.2568839e-10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0do85zh_QfM",
        "outputId": "03b25274-4efa-496a-9ba4-4ad6aeb832ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ERROR_THRESHOLD = 0.00000000001\n",
        "# generate probabilities from the model\n",
        "results = [[i, r] for i, r in enumerate(prediction[0]) if r > ERROR_THRESHOLD]\n",
        "print('Our prediction translated to classes and probabilities:\\n')\n",
        "for r in results:\n",
        "    print(classes[r[0]], round(r[1], 8))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our prediction translated to classes and probabilities:\n",
            "\n",
            "goodbye 0.99984235\n",
            "greeting 9.877e-05\n",
            "hours 2.79e-06\n",
            "mopeds 5.586e-05\n",
            "opentoday 0.0\n",
            "payments 1.7e-07\n",
            "thanks 4e-08\n",
            "today 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iekpyNa_QfN"
      },
      "source": [
        "###################################################################################\n",
        "# Let's define two needy functions to do the natural language preprocessing for us\n",
        "# and build the bag of words (bow) for us from a sentence of words\n",
        "###################################################################################\n",
        "def clean_up_sentence(sentence):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stem each word\n",
        "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "def bow(sentence, words, show_details=False):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words\n",
        "    bag = [0]*len(words)  \n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s: \n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "\n",
        "    return(np.array(bag))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy4Dh4xi_QfP",
        "outputId": "14f3788e-de31-475a-c1f9-4abe457e3a6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('These are all the words for our classification:\\n\\n', words)\n",
        "print('')\n",
        "print('Our sentence is represented by the following bag of words (bow):\\n')\n",
        "p = bow(\"Can you please tell me if you are open today?\", words, show_details=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These are all the words for our classification:\n",
            "\n",
            " [\"'d\", \"'s\", ',', 'a', 'acceiv', 'anyon', 'ar', 'at', 'bye', 'can', 'card', 'cash', 'ciao', 'credit', 'day', 'do', 'doe', 'good', 'goodby', 'hav', 'hello', 'help', 'hey', 'hi', 'ho', 'hour', 'how', 'i', 'is', 'kind', 'lat', 'lik', 'mastercard', 'mop', 'much', 'of', 'on', 'op', 'perfect', 'rent', 'see', 'so', 'tak', 'thank', 'that', 'ther', 'thi', 'tim', 'to', 'today', 'up', 'want', 'we', 'what', 'when', 'which', 'work', 'yo', 'you']\n",
            "\n",
            "Our sentence is represented by the following bag of words (bow):\n",
            "\n",
            "found in bag: can\n",
            "found in bag: you\n",
            "found in bag: you\n",
            "found in bag: ar\n",
            "found in bag: op\n",
            "found in bag: today\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ots_q0Fk_QfR",
        "outputId": "1e711e76-d130-4f90-f137-87cee2959afe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Kindly reminder: our classes we want to predict are:\\n\\n', classes)\n",
        "\n",
        "ERROR_THRESHOLD=0.0001\n",
        "prediction = model.predict(np.array([p]))\n",
        "# generate probabilities from the model\n",
        "results = [[i, r] for i, r in enumerate(prediction[0]) if r > ERROR_THRESHOLD]\n",
        "\n",
        "print('\\nOur prediction is:\\n')\n",
        "for r in results:\n",
        "    print('=> ', classes[r[0]], round(r[1],4))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kindly reminder: our classes we want to predict are:\n",
            "\n",
            " ['goodbye', 'greeting', 'hours', 'mopeds', 'opentoday', 'payments', 'rental', 'thanks', 'today']\n",
            "\n",
            "Our prediction is:\n",
            "\n",
            "=>  opentoday 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAhVmKvZ_QfS"
      },
      "source": [
        "########################################################################\n",
        "# Let's create a needy data structure to \n",
        "# (1) hold and track the user context\n",
        "# (2) classifies our sentence to a class\n",
        "# (3) generates a contextualized response for a specific user \n",
        "#        based on 3 elements\n",
        "#       (a) class with highest prediction propability\n",
        "#       (b) a specific user id\n",
        "#       (c) context set\n",
        "########################################################################\n",
        "\n",
        "# (1) hold and track the user context\n",
        "context = {}\n",
        "\n",
        "# (2) classifies our sentence to a class\n",
        "def classify(sentence):\n",
        "    # generate probabilities from the model\n",
        "    results = model.predict(np.array([bow(sentence, words)]))[0]\n",
        "    # filter out predictions below a threshold\n",
        "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], r[1]))\n",
        "    # return tuple of intent and probability\n",
        "    return return_list\n",
        "\n",
        "# (3) generates a contextualized response for a specific user\n",
        "def response(sentence, user_id='123', show_details=False):\n",
        "    results = classify(sentence)\n",
        "    # if we have a classification then find the matching intent tag\n",
        "    if results:\n",
        "        # loop as long as there are matches to process\n",
        "        while results:\n",
        "            for i in intents['intents']:\n",
        "                # find a tag matching the first result\n",
        "                if i['tag'] == results[0][0]:\n",
        "                    # set context for this intent if necessary\n",
        "                    if 'context_set' in i:\n",
        "                        if show_details: print ('context:', i['context_set'])\n",
        "                        context[user_id] = i['context_set']\n",
        "\n",
        "                    # check if this intent is contextual and applies to this user's conversation\n",
        "                    if not 'context_filter' in i or \\\n",
        "                        (user_id in context and 'context_filter' in i and i['context_filter'] == context[user_id]):\n",
        "                        if show_details: print ('tag:', i['tag'])\n",
        "                        # a random response from the intent\n",
        "                        return print(random.choice(i['responses']))\n",
        "\n",
        "            results.pop(0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld6m1EcD_QfU",
        "outputId": "6f6699d7-3cb9-40c1-b247-5eded8b6b825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "response('Hey')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi there, how can I help?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8eVcIm6_QfW",
        "outputId": "f28c1ae6-c1c6-4c84-9de4-1fcc35ce619b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classify('What are you opening times today?')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('opentoday', 1.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hx83QJ1_QfY",
        "outputId": "b22b46b6-0177-4d06-b598-5f0b85617e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "response('is your shop open today?')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our hours are 9am-9pm every day\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLuV7cZQ_QfZ"
      },
      "source": [
        "# So how does this context thing work?\n",
        "context = {}"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PrwEr6n_Qfb",
        "outputId": "9c18bf15-fbd5-47ff-bb03-942d8b5c5ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "response('Can we rent a moped?', user_id='Andreas', show_details=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "context: rentalday\n",
            "tag: rental\n",
            "Are you looking to rent today or later this week?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyJsuyVY_Qfc",
        "outputId": "fb7fc166-ffdd-4697-dfc3-b6ea3f80346c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "response('today', user_id='Andreas',show_details=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tag: today\n",
            "For rentals today please call 1-800-MYMOPED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLW8AE2J_Qfe",
        "outputId": "95c8250e-3f10-47f6-e9b1-de75b33d17c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "response('Bye bye')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bye! Looking forward to seeing you again soon!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
